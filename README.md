# Chinese MRC for HaiHua AI
CUDA_VISIBLE_DEVICES=0 python --data_dir ./data --num_choices 4 --model_type bert --task_name chn --model_name_or_path /data1/pytorch-plm-models/chinese_roberta_wwm_ext --tokenizer_name_or_path /data1/pytorch-plm-models/chinese_roberta_wwm_ext --output_dir /data1/pengwei/third/semeval_2021/src/checkpoints_sta/task_chn_lr2 --log_file /data1/pengwei/third/semeval_2021/src/log.task_chn_testlr2.out --result_eval_file /data1/pengwei/third/semeval_2021/src/result.eval.task_chn_testlr2.txt --tfboard_log_dir /data1/pengwei/third/semeval_2021/src/checkpoints_sta/task_chn_testlr2/tfboard.event.out --do_train --do_lower_case --overwrite_output_dir --max_seq_length 400 --train_batch_size 16 --per_gpu_train_batch_size 2 --per_gpu_eval_batch_size 4 --num_train_epochs 10 --learning_rate 2e-5 --gradient_accumulation_steps 4 --max_grad_norm 0.0 --seed 42 --evaluate_epoch --save_steps 1000 --eval_all_checkpoints